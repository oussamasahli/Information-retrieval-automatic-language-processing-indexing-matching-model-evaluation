{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TME2 :  Appariement\n",
    "\n",
    "L'appariement est l'action qui consiste à rassembler par paires des choses qui sont naturellement compatibles. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from tme1Indexation.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import tme1Indexation as tm\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 1 – Exercice de compréhension : modèle de RI simple\n",
    "On considère la collection de documents (cisi.txt et cacm.txt) et la liste des stopwords (TextRepresenter.py) du TME1. L’objectif dans cet exercice est d’estimer le score des documents pour la requˆete \"home sales top\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " question 1) Quels index faut-il interroger pour avoir un calcule du score pertinent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise l'index inversé , car il nous donne accès aux informations dont on a besoin pour calculer le score plus rapidement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "question 1.2) Ecrire le code qui permet de calculer le score des documents à partir du modèle booléen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ScoreBoolean retourne les documents qui contiennent tous les termes de la requête.\n",
    "Ca veut dire que j'ai considéré  que les temes de la requête sont relié par des AND entre eux.\n",
    "Remarque:\n",
    "si j'écris q=\"t1 AND (t2 OR NOT T3)\", si ça c'est ma requête alors je dois retourner les documents  qui contiennent t1 et ( t2 ou t3).\n",
    "Du coup ça dépend de la syntaxe de la requête."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "intersection  retourne la liste des documents qui contiennent tous les mots de la requete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(indexReverse,s):\n",
    "    L=[]\n",
    "    for c,v in s.items():\n",
    "        L.append(indexReverse[c])\n",
    "    d=L[0]\n",
    "    M=[]\n",
    "    for c,v in d.items():\n",
    "        M.append(c)\n",
    "    for c in M:\n",
    "        b=False\n",
    "        for D in L:\n",
    "            if (c not in D):\n",
    "                b=True\n",
    "        if(b):\n",
    "            M.remove(c)\n",
    "    return M\n",
    "    \n",
    "         \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ScoreBoolean(q,T):\n",
    "    I=tm.IndexerSimple()\n",
    "    index,indexReverse=I.indexation(T)\n",
    "    \n",
    "    PS=tm.tr.PorterStemmer()\n",
    "    s=PS.getTextRepresentation(q)\n",
    "    return intersection(indexReverse,s)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On récupère la liste des documents qui contiennent tous les mots de la requête"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "q=\"home sales top\"\n",
    "T=\"cisi/cisi.txt\"\n",
    "#print(ScoreBoolean(q,T))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "question 1.3) \n",
    "On calcule le score des documents à partir du modèle vectoriel (produit cart´esien) dans le cas d’une pond´eration tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modèle Vectoriel= Vector Space Model (VSM).\n",
    "\n",
    "On représente les documents et les requêtes sous forme de vecteurs dans l’espace vectoriel engendré par tous les termes de la collection de documents:\n",
    "\n",
    "T<t1,t2, …, tM>  (un terme = une dimension).\n",
    "\n",
    "Document : dj= (w1j, w2j, …, wMj) \n",
    "\n",
    "Requête : q= (w1q, w2q, …, wMq) \n",
    "\n",
    "wij: poids du terme ti dans le document dj : tf*idf \n",
    "\n",
    "On parle aussi de Modèle sac de mots:\n",
    "\n",
    "La représentation vectorielle ne tient pas compte de l’ordre des mots.\n",
    "\n",
    "« Un garçon manque une pomme » est représenté par le même vecteur que « une pomme mange un garçon »\n",
    "\n",
    " c’est ce que l’on appelle « Sac de mots » (Bag of words) \n",
    " \n",
    " Une collection de n documents et M termes distincts peut être représentée sous forme de matrice ( ligne : M document , colonnes: M terme de la collection)\n",
    " \n",
    " La requête est également représentée par un vecteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I=tm.IndexerSimple()\n",
    "#index,indexReverse=I.indexation(\"cisi/cisi.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nT=[]\\nfor c,v in indexReverse.items():\\n    T.append(c)\\n#La liste de tous les Documents la collection\\nD=[]\\nfor c,v in index.items():\\n    D.append(c)\\n\\n#Construction de la matrice de vecteurs de document\\nM={}\\n\\nfor d in D:\\n    di={} #vecteur associé à chaque document\\n    r=I.getTfIDFsForDoc(d)\\n    for w in T:\\n        if (w in r):\\n            di[w]=r[w] \\n        else:\\n            di[w]=0\\n    M[d]=di\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#les termes de l'index (les termes normalisé présents dans la collection)\n",
    "\"\"\"\n",
    "T=[]\n",
    "for c,v in indexReverse.items():\n",
    "    T.append(c)\n",
    "#La liste de tous les Documents la collection\n",
    "D=[]\n",
    "for c,v in index.items():\n",
    "    D.append(c)\n",
    "\n",
    "#Construction de la matrice de vecteurs de document\n",
    "M={}\n",
    "\n",
    "for d in D:\n",
    "    di={} #vecteur associé à chaque document\n",
    "    r=I.getTfIDFsForDoc(d)\n",
    "    for w in T:\n",
    "        if (w in r):\n",
    "            di[w]=r[w] \n",
    "        else:\n",
    "            di[w]=0\n",
    "    M[d]=di\n",
    "\"\"\"       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(M[\"2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construction du vecteur requete. Je normalise les termes de la reqête parceque les termes de l'indexation ont tous été normalisé\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nq=\"home sales top\"\\nPS=tm.tr.PorterStemmer()\\ns=PS.getTextRepresentation(q)\\nQ={}\\nfor w in T:\\n    if (w in s):\\n        Q[w]=s[w] \\n    else:\\n        Q[w]=0\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "q=\"home sales top\"\n",
    "PS=tm.tr.PorterStemmer()\n",
    "s=PS.getTextRepresentation(q)\n",
    "Q={}\n",
    "for w in T:\n",
    "    if (w in s):\n",
    "        Q[w]=s[w] \n",
    "    else:\n",
    "        Q[w]=0\n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La pertinence est traduite en une similarité vectorielle:\n",
    "un document est d'autant plus pertinent à une requête que le vecteur associé est similaire à celui de la requête."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le degré de correspondance de R(d,q):\n",
    "Produit scalaire des deux vecteurs:\n",
    "R(di,qk) = somme des produit des poids des termes de la reqête et ceux du document di , pour i=1,....,n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nScores={}\\nfor c,v in M.items():\\n    p=0\\n    for w in T:\\n        p=p+(v[w]*Q[w])\\n    Scores[c]=p\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Scores={}\n",
    "for c,v in M.items():\n",
    "    p=0\n",
    "    for w in T:\n",
    "        p=p+(v[w]*Q[w])\n",
    "    Scores[c]=p\n",
    "\"\"\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 2 – Projet ”Moteur de Recherche” : Etape Appariemen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Représentation pondérée des documents et de la requête\n",
    "\n",
    "Une classe générique est une classe qui peut être réutilisée pour des objets de différents types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Weighter:\n",
    "    \n",
    "    def __init__(self,T):\n",
    "        self.I=tm.IndexerSimple()\n",
    "        self.index,self.indexReverse=self.I.indexation(T)\n",
    "        self.mots=[c for c,v in self.indexReverse.items()] #récupère tous les mots de la collection\n",
    "        self.docs=[c for c,v in self.index.items()] #répère la liste de tous les id des documents de la collection\n",
    "     \n",
    "     #getWeightsForDoc retourne les poids des termes pour un document dont l’identiﬁant est idDoc\n",
    "        \n",
    "    def getWeightsForDoc(self,idDoc):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    \n",
    "    #getWeightsForStem retourne les poids du terme stem pour tous les documents qui le contiennent\n",
    "    \n",
    "    def  getWeightsForStem(self,stem):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    \n",
    "    #getWeightsForQuery retourne les poids des termes de la requˆete\n",
    "    \n",
    "    def  getWeightsForQuery(self,query):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w t,d = tf t,d et w t,q = 1 si t ∈ q, O sinon;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Weighter1(Weighter):\n",
    "    \n",
    "    def __init__(self,T):\n",
    "        self.I=tm.IndexerSimple()\n",
    "        self.index,self.indexReverse=self.I.indexation(T)\n",
    "        self.mots=[c for c,v in self.indexReverse.items()] #récupère tous les mots de la collection\n",
    "        self.docs=[c for c,v in self.index.items()] #répère la liste de tous les id des documents de la collection\n",
    "     \n",
    "    def getWeightsForDoc(self,idDoc):\n",
    "        d=self.index[idDoc]    \n",
    "        for m in self.mots:   #tous les termes de la collection qui ne sont pas dans ce doc ont un poid de 0\n",
    "            if(m not in d):\n",
    "                d[m]=0\n",
    "        return d\n",
    "    \n",
    "    def  getWeightsForStem(self,stem):\n",
    "        return self.indexReverse[stem]\n",
    "   \n",
    "    def  getWeightsForQuery(self,query):\n",
    "        PS=tm.tr.PorterStemmer()\n",
    "        s=PS.getTextRepresentation(query)\n",
    "        q={}\n",
    "        for m in self.mots:\n",
    "            if(m in s):\n",
    "                q[m]=1\n",
    "            else:\n",
    "                q[m]=0\n",
    "        return q\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w=Weighter1(\"cisi/cisi.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test:\n",
    "on affiche le poid de tous les terme (normalisé) de la collection pour le document dont l'id est 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(w.getWeightsForDoc(\"1\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on affiche le poid du mot \"present\"  \"seulement\" pour les documents qui le contient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(w.getWeightsForStem(\"present\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on affiche pour chaque terme de la collection le poid de ce terme pour la reqête"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(w.getWeightsForQuery(\"home saled top\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w t,d = tf t,d et w t,q = tf t,q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Weighter2(Weighter):\n",
    "    \n",
    "    def __init__(self,T):\n",
    "        self.I=tm.IndexerSimple()\n",
    "        self.index,self.indexReverse=self.I.indexation(T)\n",
    "        self.mots=[c for c,v in self.indexReverse.items()] #récupère tous les mots de la collection\n",
    "        self.docs=[c for c,v in self.index.items()] #répère la liste de tous les id des documents de la collection\n",
    "     \n",
    "    def getWeightsForDoc(self,idDoc):\n",
    "        d=self.index[idDoc]    \n",
    "        for m in self.mots:   #tous les termes de la collection qui ne sont pas dans ce doc ont un poid de 0\n",
    "            if(m not in d):\n",
    "                d[m]=0\n",
    "        return d\n",
    "    \n",
    "    def  getWeightsForStem(self,stem):\n",
    "        return self.indexReverse[stem]\n",
    "   \n",
    "    def  getWeightsForQuery(self,query):\n",
    "        PS=tm.tr.PorterStemmer()\n",
    "        s=PS.getTextRepresentation(query)\n",
    "        q={}\n",
    "        for m in self.mots:\n",
    "            if(m in s):\n",
    "                q[m]=s[m]   #il y a que cette ligne qui a changé\n",
    "            else:\n",
    "                q[m]=0\n",
    "        return q\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w t,d = tf t,d et w t,q = idf t si t ∈ q, 0 sinon;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Weighter3(Weighter):\n",
    "    \n",
    "    def __init__(self,T):\n",
    "        self.I=tm.IndexerSimple()\n",
    "        self.index,self.indexReverse=self.I.indexation(T)\n",
    "        self.mots=[c for c,v in self.indexReverse.items()] #récupère tous les mots de la collection\n",
    "        self.docs=[c for c,v in self.index.items()] #répère la liste de tous les id des documents de la collection\n",
    "     \n",
    "    def getWeightsForDoc(self,idDoc):\n",
    "        d=self.index[idDoc]    \n",
    "        for m in self.mots:   #tous les termes de la collection qui ne sont pas dans ce doc ont un poid de 0\n",
    "            if(m not in d):\n",
    "                d[m]=0\n",
    "        return d\n",
    "    \n",
    "    def  getWeightsForStem(self,stem):\n",
    "        return self.indexReverse[stem]\n",
    "   \n",
    "    def  getWeightsForQuery(self,query):\n",
    "        PS=tm.tr.PorterStemmer()\n",
    "        s=PS.getTextRepresentation(query)\n",
    "        q={}\n",
    "        N=len(self.docs)\n",
    "        for m in self.mots:\n",
    "            if(m in s):\n",
    "                idf=math.log( (1+N) / (1+len(self.indexReverse[m])) )\n",
    "                q[m]=idf \n",
    "            else:\n",
    "                q[m]=0\n",
    "        return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w=Weighter3(\"cisi/cisi.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(w.getWeightsForQuery(\"home saled top\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " w t,d = 1 + log(tf t,d) si t ∈ d, 0 sinon; et w t,q = idf t si t ∈ q, 0 sinon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Weighter4(Weighter):\n",
    "    \n",
    "    def __init__(self,T):\n",
    "        self.I=tm.IndexerSimple()\n",
    "        self.index,self.indexReverse=self.I.indexation(T)\n",
    "        self.mots=[c for c,v in self.indexReverse.items()] #récupère tous les mots de la collection\n",
    "        self.docs=[c for c,v in self.index.items()] #répère la liste de tous les id des documents de la collection\n",
    "     \n",
    "    def getWeightsForDoc(self,idDoc):\n",
    "        d=self.index[idDoc]    \n",
    "        di={}\n",
    "        for m in self.mots:   #tous lew=Weighter3(\"cisi/cisi.txt\")s termes de la collection qui ne sont pas dans ce doc ont un poid de 0\n",
    "            if(m in d):\n",
    "                di[m]=1+math.log(d[m])\n",
    "            else:\n",
    "                di[m]=0\n",
    "        return di\n",
    "    \n",
    "    def  getWeightsForStem(self,stem):\n",
    "        r=self.indexReverse[stem]\n",
    "        d={}\n",
    "        for c,v in r.items():\n",
    "            d[c]=1+math.log(v)\n",
    "        return d\n",
    "   \n",
    "    def  getWeightsForQuery(self,query):\n",
    "        PS=tm.tr.PorterStemmer()\n",
    "        s=PS.getTextRepresentation(query)\n",
    "        q={}\n",
    "        N=len(self.docs)\n",
    "        for m in self.mots:\n",
    "            if(m in s):\n",
    "                idf=math.log( (1+N) / (1+len(self.indexReverse[m])) )\n",
    "                q[m]=idf \n",
    "            else:\n",
    "                q[m]=0\n",
    "        return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w=Weighter4(\"cisi/cisi.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(w.getWeightsForDoc(\"1\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(w.getWeightsForStem(\"present\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " wt,d = (1 + log(tf t,d))x idf t si t ∈ d, 0 sinon; et wt,q = (1 + log(tf t,q))x idf t si t ∈ q, 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Weighter5(Weighter):\n",
    "    \n",
    "    def __init__(self,T):\n",
    "        self.I=tm.IndexerSimple()\n",
    "        self.index,self.indexReverse=self.I.indexation(T)\n",
    "        self.mots=[c for c,v in self.indexReverse.items()] #récupère tous les mots de la collection\n",
    "        self.docs=[c for c,v in self.index.items()] #répère la liste de tous les id des documents de la collection\n",
    "     \n",
    "    def getWeightsForDoc(self,idDoc):\n",
    "        d=self.index[idDoc]    \n",
    "        di={}\n",
    "        N=len(self.docs)\n",
    "        for m in self.mots:   #tous lew=Weighter3(\"cisi/cisi.txt\")s termes de la collection qui ne sont pas dans ce doc ont un poid de 0\n",
    "            if(m in d):\n",
    "                idf=math.log( (1+N) / (1+len(self.indexReverse[m])) )\n",
    "                di[m]=(1+math.log(d[m]))*idf\n",
    "            else:\n",
    "                di[m]=0\n",
    "        return di\n",
    "    \n",
    "    def  getWeightsForStem(self,stem):\n",
    "        r=self.indexReverse[stem]\n",
    "        d={}\n",
    "        N=len(self.docs)\n",
    "        idf=math.log( (1+N) / (1+len(r)) )\n",
    "        for c,v in r.items():           \n",
    "            d[c]=(1+math.log(v))*idf\n",
    "        return d\n",
    "   \n",
    "    def  getWeightsForQuery(self,query):\n",
    "        PS=tm.tr.PorterStemmer()\n",
    "        s=PS.getTextRepresentation(query)\n",
    "        q={}\n",
    "        N=len(self.docs)\n",
    "        for m in self.mots:\n",
    "            if(m in s):\n",
    "                idf=math.log( (1+N) / (1+len(self.indexReverse[m])) )\n",
    "                q[m]=(1+math.log(s[m]))*idf \n",
    "            else:\n",
    "                q[m]=0\n",
    "        return q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Modèles de RI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IRModel:\n",
    "    \n",
    "    def __init__(self,T):\n",
    "        self.I=tm.IndexerSimple()\n",
    "        self.index,self.indexReverse=I.indexation(T)\n",
    "        self.mots=[c for c,v in self.indexReverse.items()] #récupère tous les mots de la collection\n",
    "        self.docs=[c for c,v in self.index.items()] #répère la liste de tous les id des documents de la collection\n",
    "     \n",
    "    def  getScores(self,query):   # retourne les scores des documents pour une requête\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def getRanking(self,query): # retourne une liste de couples (document-score) ordonn´ee par score d´ecroissante\n",
    "        scores=self.getScores(query)\n",
    "        return sorted(scores.items(), key=lambda t: t[1],reverse=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "question 2.2) \n",
    "\n",
    "Déﬁnir une classe Vectoriel qui hérite de IRModel. Elle comporte en paramètres un Weighter déﬁni dans l’´etape précédente ainsi qu’un booléen normalized permettant de déﬁnir la fonction de score (produit scalaire si faux et score cosinus si vrai). \n",
    "( les normes des vecteurs des documents ne doivent pas être calculés à chaque nouvelle requête ).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectoriel(IRModel):\n",
    "    \n",
    "    def __init__(self,weighter, normalized):\n",
    "        self.weighter=weighter\n",
    "        self. normalized= normalized\n",
    "        self.nd={}\n",
    "        self.M={}\n",
    "        \n",
    "        for d in self.weighter.docs:\n",
    "            self.M[d]=self.weighter.getWeightsForDoc(d) # pour chaque document de la collection , on récupère la liste des poids de chaque termes de la collection\n",
    "   \n",
    "        for c,v in self.M.items():\n",
    "                d2=[]\n",
    "                for ca,va in v.items():\n",
    "                    d2.append(va*va)\n",
    "                self.nd[c]=math.sqrt(sum(d2))  #on calcule la norme de chaque document\n",
    "\n",
    "    def getScores(self,query):\n",
    "        Scores={}\n",
    "        q=self.weighter.getWeightsForQuery(query)\n",
    "        for c,v in self.M.items():\n",
    "                p=0              \n",
    "                for w in self.weighter.mots:\n",
    "                    p=p+(v[w]*q[w])\n",
    "                Scores[c]=p        \n",
    "                \n",
    "        if(self.normalized):\n",
    "            q2=[]\n",
    "            for c,v in q.items():\n",
    "                q2.append(v*v)\n",
    "                \n",
    "            nq=math.sqrt(sum(q2))\n",
    "            Scores2={}\n",
    "            \n",
    "            for c,v in Scores.items():\n",
    "                Scores2[c]=v/(self.nd[c]*nq)  \n",
    "            Scores=Scores2\n",
    "            \n",
    "        return Scores\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#V=Vectoriel(w,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#S=V.getScores(\"home saled top\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#V=Vectoriel(w,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#S=V.getScores(\"home saled top\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(S)\n",
    "#print(V.getRanking(\"home saled top\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "question 2.3) Déﬁnir les classes ModeleLangue et Okapi permettant de calculer les scores pour respectivement le modèle de langue (lissage Jelinek-Mercer) et Okapi-BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle de langue :\n",
    "Un modèle de langue est défini par son vocabulaire (mots simples, séquence de mots).\n",
    "Chaque mot (m)/séquence de mots(m1m2..mn) a une probabilité d’être généré(e).\n",
    "Le but est de calculer --> P(s|M):\n",
    "\n",
    "    -s une observation (séquence de mots/texte) quelconque \n",
    "    -Probabilité d’observer s dans le modèle (la langue) M\n",
    "Définir la taille des séquences générées par le modèle ? \n",
    "\n",
    "    --> Séquence de 1 mot, 2 mots, 3 mots, … \n",
    " \n",
    "Estimer le modèle à probabilité de chaque séquence générée ? \n",
    "\n",
    "Calculer la probabilité d’une observation (un texte) quelconque? \n",
    "\n",
    "On choisit : Séquence d’un mot --> modèle unigram .  soit s une observation (un texte) de n mots s=m1 m2…mn .\n",
    "\n",
    "Unigram – (M génère des séquences de 1 mot) . P(S|M)= P(m1m2....mn)= produit des P(mi|M) , pour i=1,....,n.\n",
    "\n",
    "UNigram : P(mi | M) = tf (mi) /nombre total de mots dans M.:\n",
    "\n",
    "Problème des fréquences nulles (zéro) :\n",
    "\n",
    "    -Si un événement (un mot de la séquence) n’apparait pas dans le modèle, le modèle lui assigne une probabilité  0 \n",
    "    -Solution : assigner des probabilités différentes de zéro aux événements (mots) absents\n",
    "\n",
    "Lissage par interpolation :\n",
    "\n",
    "    - Les méthodes de « discounting »  traitent les mots qui n’apparaissent pas dans le corpus de la même manière. Or, il y a des mots qui peuvent être plus fréquents que d’autres \n",
    "    -Solution – Interpoler le modèle en utilisant d’autres sources d’évidence (par exemple la collection de documents) \n",
    "\n",
    "Interpolation  (Jelinek-Mercer) :\n",
    "\n",
    "    -RSV(Q,d)= Produit ( (1-lambda) * p(t|Mc) + lambda*p(t|Md)), pourtous les termes t de la requête.\n",
    "    P(t|Mc)=p(t)=frequence du terme t dans la collection / somme des fréquence de tous les termes de la collection\n",
    "    -(λ=0.8 pour les requêtes courtes et 0.2 pour les requêtes longues) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModeleLangue(IRModel):\n",
    "    \n",
    "    def __init__(self,weighter,l):\n",
    "        self.weighter=weighter        \n",
    "        L=[sum(v.values()) for c,v in self.weighter.indexReverse.items()]\n",
    "        self.total=sum(L)\n",
    "        self.l=l\n",
    "        \n",
    "    def ptD(self,t,d):\n",
    "        s=sum(d.values())\n",
    "        if(t in d):\n",
    "            return d[t]/s\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def ptC(self,t):      \n",
    "        if(t in self.weighter.indexReverse):    \n",
    "            return sum(self.weighter.indexReverse[t].values()) / self.total\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def getScores(self,query):\n",
    "        PS=tm.tr.PorterStemmer()\n",
    "        s=PS.getTextRepresentation(query)\n",
    "        Scores={}\n",
    "        for d in self.weighter.docs:\n",
    "            p=1\n",
    "            for m,v in s.items():\n",
    "                p=p*( (1-self.l) * self.ptC(m) + self.l*self.ptD(m,self.weighter.index[d]))\n",
    "            Scores[d]=p\n",
    "        return Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#M=ModeleLangue(w,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(M.getScores(\"home saled top\"))\n",
    "#print(M.getRanking(\"home saled top\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Okapi-BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Okapi(IRModel):\n",
    "    \n",
    "    def __init__(self,weighter,k,b):\n",
    "        self.weighter=weighter  \n",
    "        self.k=k\n",
    "        self.b=b\n",
    "\n",
    "        \n",
    "    def getScores(self,query):\n",
    "        Scores={}\n",
    "        PS=tm.tr.PorterStemmer()\n",
    "        s=PS.getTextRepresentation(query)\n",
    "        avgdl=0\n",
    "        L=[]\n",
    "        \n",
    "        for c,v in self.weighter.index.items():\n",
    "            t=sum(v.values())\n",
    "            L.append(t)\n",
    "        avgdl=(sum(L)/len(self.weighter.index))\n",
    "        \n",
    "        for d in self.weighter.docs:\n",
    "            t=self.weighter.index[d]\n",
    "            D=sum(t.values())\n",
    "            for c,v in s.items():\n",
    "                sc=0\n",
    "                #ATTENTION : SI LE MOT DE LA REQUETE NE FIGURE PAS DANS L'INDEXINVERSE \n",
    "                if(c not in self.weighter.indexReverse ):\n",
    "                    n=0\n",
    "                else:\n",
    "                    n=self.weighter.indexReverse[c]\n",
    "                idf=math.log( (1+len(self.weighter.docs)) / (1+len(n)))\n",
    "        \n",
    "                if(c in t):\n",
    "                    tf=t[c]\n",
    "                else:\n",
    "                    tf=0\n",
    "                if( (tf + self.k * (1-self.b+self.b*(D/avgdl))) != 0 ):\n",
    "                    sc=sc + idf * ( ( tf*(self.k+1) ) / ( tf + self.k * (1-self.b+self.b*(D/avgdl)) ) )\n",
    "            Scores[d]=sc\n",
    "        return Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#M=Okapi(w,1.2,0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(M.getRanking(\"home saled top\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Bonus - Très fortement conseillés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "question 2.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Q=[\"convention depth  week profil\",\"object issu assign\", \"inter feeder result \" , \n",
    "   \"emphasi length demonstrat organ\" , \"group receipt connect relev\", \"run fundament assign librari\",\n",
    "  \"vindic howel  baxter data\", \"mechan timeli physical negoti\", \"mari historiograph desper demonstrat\",\n",
    "  \"home saled top\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " On sépare l’ensemble des requêtes en deux ensembles (train/test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= Q[:int(len(Q)/2)]\n",
    "test= Q[int(len(Q)/2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train)\n",
    "#print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On déﬁnit une grille de valeurs à tester (de 0 à 1 par pas de 0.1). \n",
    "\n",
    "On expérimente chaque combinaison possible pour chaque modèle sur le jeu de données train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rappel : il y a 4 classe weighter différentes , chacune a sa façon de calculer le poid d'un terme pourla requête et le poid d'un terme pour le document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test sur l'ensemble \"train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Modele Langue\n",
    "\n",
    "Dans le modèle de langue il y a un seul paramètre qui varie (c'est le lambda). \n",
    "(Voir en haut à quoi correspond ce lambda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w=Weighter1(\"cisi/cisi.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque valeur de lambda , on cré un modele de langue parametré avec ce lambda. Ensuite pour ce modèle de langue , on parcourt chaque requête dans l'ensemble train , et on calcule pour chacune de ces reqête le score associé à chaque document de la collection \"cisi.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nG={}\\nfor i in np.arange(0,1.1,0.1):\\n    ML=ModeleLangue(w,i)\\n    d={}\\n    for c in train:\\n        scores=ML.getRanking(c)\\n        d[c]=scores\\n    G[i]=d\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "G={}\n",
    "for i in np.arange(0,1.1,0.1):\n",
    "    ML=ModeleLangue(w,i)\n",
    "    d={}\n",
    "    for c in train:\n",
    "        scores=ML.getRanking(c)\n",
    "        d[c]=scores\n",
    "    G[i]=d\n",
    "\"\"\"       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(G[0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation : pour chaque valeur de lambda , on obtient pour chaque requête un ensemble de scores de documents différent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Modele Vectoriel\n",
    "\n",
    "Sur ce modèle il n'y a pas de paramètres.\n",
    "Mais il peut être intéressant de changer notre weighter , car chaque weighter a sa manière de calculer le vecteur de poid des documents et de la requête"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nw1=Weighter1(\"cisi/cisi.txt\")\\nw2=Weighter2(\"cisi/cisi.txt\")\\nw3=Weighter3(\"cisi/cisi.txt\")\\nw4=Weighter4(\"cisi/cisi.txt\")\\nw5=Weighter5(\"cisi/cisi.txt\")\\n\\nW=[w1,w2,w3,w4,w5]\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "w1=Weighter1(\"cisi/cisi.txt\")\n",
    "w2=Weighter2(\"cisi/cisi.txt\")\n",
    "w3=Weighter3(\"cisi/cisi.txt\")\n",
    "w4=Weighter4(\"cisi/cisi.txt\")\n",
    "w5=Weighter5(\"cisi/cisi.txt\")\n",
    "\n",
    "W=[w1,w2,w3,w4,w5]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGw={}\\ni=1\\nfor w in W:\\n    V=Vectoriel(w,False)  # normalized = false  , on a utilisé la similarité produit scalaire\\n    d={}\\n    for c in train:\\n        scores=V.getRanking(c)\\n        d[c]=scores\\n    Gw[str(i)]=d\\n    i+=1\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Gw={}\n",
    "i=1\n",
    "for w in W:\n",
    "    V=Vectoriel(w,False)  # normalized = false  , on a utilisé la similarité produit scalaire\n",
    "    d={}\n",
    "    for c in train:\n",
    "        scores=V.getRanking(c)\n",
    "        d[c]=scores\n",
    "    Gw[str(i)]=d\n",
    "    i+=1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Gw['4'])\n",
    "#print(Gw['5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation : pour des weighter différents , sur chaque modele Vectoriel construit , on remarque que l'ordre des documents classé selon leur score,  obtenue sur chaque reqête , est à peu près le même"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Modele Okapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque valeur de k et b , on cré un modele Okapi parametré avec ce k et ce b. Ensuite pour ce modèle Okapi , on parcourt chaque requête dans l'ensemble train , et on calcule pour chacune de ces reqête le score associé à chaque document de la collection \"cisi.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nG={}\\nfor k in np.arange(0,1.1,0.1):\\n    for b in np.arange(0,1.1,0.1):\\n        Mo=Okapi(w,k,b)\\n        d={}\\n        for c in train:\\n            scores=Mo.getRanking(c)\\n            d[c]=scores\\n        G[(k,b)]=d\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "G={}\n",
    "for k in np.arange(0,1.1,0.1):\n",
    "    for b in np.arange(0,1.1,0.1):\n",
    "        Mo=Okapi(w,k,b)\n",
    "        d={}\n",
    "        for c in train:\n",
    "            scores=Mo.getRanking(c)\n",
    "            d[c]=scores\n",
    "        G[(k,b)]=d\n",
    "\"\"\"       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(G[(0.0,0.0)])\n",
    "#print(G[(1.0,0.8)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que pour des valeurs de paramètres différents sur k et b , on obtient des scores de documents différents  sur chacune des requêtes, mais l'ordre de pertinence des documents sur chacune des reqêtes n'a pas l'air de changer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on pourra tester dans le TME 3 la combinaison qui obtient la meilleure valeur de métrique (MAP, Pr´ecision, ...)\n",
    "\n",
    "on applique ces valeurs sur le jeu de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test sur l'ensemble \"test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model Langue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nG={}\\nfor i in np.arange(0,1.1,0.1):\\n    ML=ModeleLangue(w,i)\\n    d={}\\n    for c in test:\\n        scores=ML.getRanking(c)\\n        d[c]=scores\\n    G[i]=d\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "G={}\n",
    "for i in np.arange(0,1.1,0.1):\n",
    "    ML=ModeleLangue(w,i)\n",
    "    d={}\n",
    "    for c in test:\n",
    "        scores=ML.getRanking(c)\n",
    "        d[c]=scores\n",
    "    G[i]=d\n",
    "\"\"\"       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(G[0.8])\n",
    "#print(G[0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation : pour des valeurs de lambda différentes , on obtient à peu près le même ordre score de pertinence.\n",
    "C'est la valeur associé à chacun des scores qui change , mais cela n'a pas l'air de modifier l'ordre de pertience des documents sur chaque requête."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nG={}\\nfor k in np.arange(0,1.1,0.1):\\n    for b in np.arange(0,1.1,0.1):\\n        Mo=Okapi(w,k,b)\\n        d={}\\n        for c in test:\\n            scores=Mo.getRanking(c)\\n            d[c]=scores\\n        G[(k,b)]=d\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "G={}\n",
    "for k in np.arange(0,1.1,0.1):\n",
    "    for b in np.arange(0,1.1,0.1):\n",
    "        Mo=Okapi(w,k,b)\n",
    "        d={}\n",
    "        for c in test:\n",
    "            scores=Mo.getRanking(c)\n",
    "            d[c]=scores\n",
    "        G[(k,b)]=d\n",
    "\"\"\"        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(G[(0.5,0.2)])\n",
    "#print(G[(0.9,0.4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2.5) \n",
    "\n",
    "C'est très flou.\n",
    "\n",
    "A la base , le but de la cross validation c'est de trouver le meilleur partionnement possible pour construire notre ensemble d'apprentissage et notre ensemble de test. Ce partionnement est important car il va nous permettre de construire le meilleur modèle possible à partir de la base d'apprentissage. Le  but étant de garder un maximum d'exemple dans notre base d'apprentissage.  Pour trouver le meilleur partionnement possible , on va diviser notre ensemble d'exemple en k folds.\n",
    "(Le but étant de faire varier la valeur de k pour trouver le meilleur partionnement possible --> à la fin lensemble d'apprentissage représentera   k-1/k de l'ensemble original , et l'ensemble de test représentera  1/k de l'ensemble original).\n",
    "\n",
    "\n",
    "On sépare le jeu de données en k folds et on procède à une cross validation. Chaque fold est successivement utilisé pour l’étape de test alors que les autres sont utilisés pour le train.\n",
    "Pour trouver le meilleur k , lors de chaque valeurde k séléctionné,on fait la moyenne du taux d'erreur de test ( quand on choisit de prendre 1 fold pour le test et les autres pour l'entrainement , on obtient un score sur le taux d'erreur de test. La moyenne se fait sur les différents scores obtenue). \n",
    "\n",
    "A la fin , on récupère la valeur de k qui nous a permis d'obtenir une moyenne du taux d'erreur la plus faible.\n",
    "\n",
    "\n",
    "Le Problème , c'est que dans notre cas à nous , je ne comprend pas comment le modèle apprend , car si je lui donne un ensemble de requête , il me donne le score des documents de la collection sur chaqune de ces reqêtes. Je ne vois où est la prédiciton dans tous ça.\n",
    "\n",
    "De plus si notre objectif c'est de chercher k , alors comment mettre les bons paramètre pour constuire notre modèle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
