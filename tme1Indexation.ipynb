{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TME1: Indexation \n",
    "\n",
    "Indexation = processus informatique consistant à référencer des données (documents,mot-clés,etc..) , de manière à faliciter leur accès ou leur traitement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import porter\n",
    "import math\n",
    "import re\n",
    "import TextRepresenter as tr\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice1 de compréhension: Indexation d'un petit jeu de donnée\n",
    "\n",
    "1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1=\"the new home has been saled on top forecasts\"\n",
    "stopwords=[\"the\", \"a\", \"an\", \"on\", \"behind\", \"under\", \"there\", \"in\", \"on\"] \n",
    "#les stopwords sont les mots vide. Il est inutile de les compter, parceque ce sont des mots qu'on a l'habitude de retrouver\n",
    "#dans la plupart des documents.\n",
    "L=doc1.split()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On enlève les stopWords de la liste de mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopwords(L,S):\n",
    "    for e in L:\n",
    "        if e in S:\n",
    "            L.remove(e)\n",
    "    return L\n",
    "\n",
    "L=removeStopwords(L,stopwords)\n",
    "#print(L)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va normaliser les mots contenus dans la liste.\n",
    "La normalisation consiste à retirer le suffixe des termes qui se ressemblent, afin de les associer ensemble lors du comptage de mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normaliser(L):\n",
    "    R=[]\n",
    "    for e in L:\n",
    "        R.append(porter.stem(e))\n",
    "    return R\n",
    "\n",
    "L=Normaliser(L)\n",
    "#print(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant pour chaque terme , on doit compter le nombre de fois où il apparait dans le document.\n",
    "On va utiliser Counter qui va nous faciliter le travail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counter:\n",
    "on peut aussi l'initialiser avec une liste, et chaque élément aura alors un compte de 1 si les éléments ne sont pas répétés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = collections.Counter(L)\n",
    "#print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "question 1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le fichier index = il indique pour chaque document,  le nombre d'occurence de chaque termes apparaissant dans le document.\n",
    "On le représente ici sous la forme d'un dictionnaire. Où chaque id d'un document est représenté par la clé du dictionnaire , et la valeur associée à chaque clé est un dictionnaire , comptant le nombre d'occurence de chaque mot apparaisant dans le document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1=\"the new home has been saled on top forecasts\" \n",
    "doc2=\"the home sales rise in july\" \n",
    "doc3=\"there is an increase in home sales in july\" \n",
    "doc4=\"july encounter a new home sales rise\"\n",
    "L=[doc1,doc2,doc3,doc4]\n",
    "\n",
    "index={}\n",
    "i=0\n",
    "for d in L:\n",
    "    E=d.split()\n",
    "    E=removeStopwords(E,stopwords)\n",
    "    E=Normaliser(E)\n",
    "    c = collections.Counter(E)\n",
    "    index[i]=c\n",
    "    i+=1\n",
    "\n",
    "#print(index)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le fichier index inversé = Pour chaque mot rencontré dans les documents , on indique quels sont les documents qui contiennent ce mot, et le nombre d'occurence de ce mot dans le document. On le représente avec un dictionnaire , où les clés sont les mots, et la valeur associé à chaque clé est un dictionnaire indiquant pour chaque document contenant ce mot le nombre d'occurence de ce mot dans le document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etape1:on récupère tous les différents mots qui apparaisent dans les documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=[]\n",
    "for d in L:\n",
    "    E=d.split()\n",
    "    E=removeStopwords(E,stopwords)\n",
    "    E=Normaliser(E)\n",
    "    for e in E:\n",
    "        if e not in M:\n",
    "            M.append(e)\n",
    "#print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexReverse={}\n",
    "for m in M:\n",
    "    d={}\n",
    "    for c,v in index.items():\n",
    "        if(m in v):\n",
    "            d[c]=v[m]\n",
    "    indexReverse[m]=d\n",
    "    \n",
    "#print(indexReverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "question 1.3)\n",
    "\n",
    "Term Frequency tf (ti,d) : nombre occurrences de ti dans le document d.\n",
    "Remarque : varie en fonction de la taille des documents. Si on double la taille des documents, tf double. Le document sera considéré comme plus pertinent.\n",
    "\n",
    "Inverse Document ferequency idf:\n",
    "\n",
    "idf (ti)=log( 1+N / 1+ df(ti))\n",
    "\n",
    "df (ti) : nombre de documents contenant ti \n",
    "\n",
    "idf (ti) : fréquence inverse, décroit vers 0 si ti apparait dans tous les documents. ( car log(1)=0 ).\n",
    "\n",
    "N : nombre de documents\n",
    "\n",
    "• TF-IDF\n",
    "\n",
    "xi =tf (ti,d)∗idf (ti)\n",
    "\n",
    "On va créer un dictionnaire où pour chaque terme ti on calcule le xi associé pour chaque doc où le terme apparait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "D={}\n",
    "N=4\n",
    "for m in M:\n",
    "    d={}\n",
    "    idf=math.log( (1+N) / (1+len(indexReverse[m])) )\n",
    "    v=indexReverse[m]\n",
    "    for c,va in v.items():\n",
    "        tf=va\n",
    "        x=tf*idf\n",
    "        d[c]=x\n",
    "    D[m]=d\n",
    "#print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice 2: parsing d'un fichier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parser un fichier est l’action d’exploiter un fichier sous une forme brute afin d’en tirer les informations utiles.\n",
    "Afin de faciliter le traitement de l’information, on a tendance à parser le fichier afin d’en soutirer les informations importantes et les insérer dans une base de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " buildDocCollectionSimple  lit le ﬁchier ligne par ligne et récupère le contenu des balises.\n",
    " On stocke dans un dictionnaire tous les documents contenues dans le fichier brut .txt.\n",
    " Pour chaque document on cré un dictionnaire contenant tous les balises qui lui correspond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDocCollectionSimple(T):\n",
    "    file = open(T, \"r\")\n",
    "    lines = file.readlines()\n",
    "    file.close()\n",
    "    D={}\n",
    "    f=True\n",
    "    p=True\n",
    "    i=0\n",
    "    s=\"\"\n",
    "\n",
    "    for line in lines:\n",
    "        if ( re.match(r\"^\\.I \\d+$\",line.strip()) ):  \n",
    "            if(p):\n",
    "                p=False\n",
    "            else:\n",
    "                d[v]=s\n",
    "                s=\"\"\n",
    "                D[i]=d\n",
    "                i+=1\n",
    "\n",
    "            d={}\n",
    "            f=True\n",
    "            m = re.search(r\"^\\.I (?P<id>\\d+)$\",line.strip())\n",
    "            if m is not None:\n",
    "                v=m.group('id')\n",
    "                d[\".I\"]=v\n",
    "        elif ( re.match(r\"^\\.\\w$\",line.strip()) ):\n",
    "            if(f):\n",
    "                f=False\n",
    "                t = re.search(r\"^\\.(?P<b>\\w)$\",line.strip())\n",
    "                if t is not None:\n",
    "                    v=t.group('b')\n",
    "                    v=\".\"+v\n",
    "                    d[v]=\"\"\n",
    "\n",
    "            else:\n",
    "\n",
    "                d[v]=s\n",
    "                s=\"\"\n",
    "                t = re.search(r\"^\\.(?P<b>\\w)$\",line.strip())\n",
    "                if t is not None:\n",
    "                    v=t.group('b')\n",
    "                    v=\".\"+v\n",
    "                    d[v]=\"\"\n",
    "\n",
    "\n",
    "        else:\n",
    "            s=s+line.strip()+\" \"\n",
    "\n",
    "\n",
    "    d[v]=s        \n",
    "    D[i]=d\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=buildDocCollectionSimple('cacmShort-good.txt')\n",
    "#print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Pour chaque document, on affiche son identiﬁant et son texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for c,v in D.items():\n",
    "#    print(\"identifiant:\",v['.I'],\" texte: \",v['.T'],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "question 2.2)\n",
    "\n",
    "buildDocumentCollectionRegex récupère le contenu des balises ”.I” et ”.T” de chaque document contenu dans le fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDocumentCollectionRegex(T):\n",
    "    D=buildDocCollectionSimple(T)\n",
    "    d={}\n",
    "    for c,v in D.items():\n",
    "        if('.T' in v):\n",
    "            d[v['.I']]=v['.T']\n",
    "        else:\n",
    "            d[v['.I']]=\"\"\n",
    "    return d\n",
    "\n",
    "#print(buildDocumentCollectionRegex('cacmShort-good.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(buildDocumentCollectionRegex('cacm/cacm.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice 3 – Projet ”Moteur de Recherche” : Etape Indexation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "question 3.1)\n",
    "\n",
    "Les documents sont stockés sous forme d’objets Document pour lesquels on peut accéder aux valeurs de l’identiﬁant et du texte. On peut egalement stocker les autres métadonnées qui permettront d’avoir un aﬃchage plus complet. Implémenter la classe Document qui servira de base au parsing de la collection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document:\n",
    "\n",
    "    def __init__(self,i,t):\n",
    "        self.id=i\n",
    "        self.texte=t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "question 3.2)\n",
    "\n",
    " la classe Parser qui permet de parser la collection stock´ee sous la forme d’un dictionnaire de Documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.Dic={}\n",
    "        \n",
    "    def parser(self,T):\n",
    "        D=buildDocumentCollectionRegex2(T)\n",
    "        for c,v in D.items():\n",
    "            self.Dic[c]=Document(c,v)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "question 3.3)\n",
    "\n",
    "la classe IndexerSimple qui permet d’indexer une collection dans une m´ethode indexation. Pour cela, vous pourrez utiliser la classe TextRepresenter.py associ´ee à la classe porter.py qui permet de normaliser une chaine de caractères.\n",
    "On souhaite ensuite construire les ﬁchiers index (index + index invers´e) des collections qui ont ´et´e pars´ees. Les ﬁchiers index devront ˆetre ´ecrits dans des ﬁchiers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "buildDocumentCollectionRegex2 récupère le contenu des balises ”.I” et ”.W” de chaque document contenu dans le fichier.\n",
    "J'en ai fais une deuxieme parceque cette fois le texte est dans la balise .W\n",
    "Dans cacm.txt , la balise \".W\" n'est pas toujours présente pour un document.\n",
    "Du coups je décide de dire que si il y a pas de texte pour un document , alors je prends la chaine vide .\n",
    "\n",
    "\n",
    "getTfsForDoc() retourne la représentation (stem-tf) d’un document a partir de l’index. C'est à dire que pour un id de document , on récupère un dictionnaire contenant tous les tf des mots présents dans le document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDocumentCollectionRegex2(T):\n",
    "    D=buildDocCollectionSimple(T)\n",
    "    d={}\n",
    "\n",
    "    for c,v in D.items():\n",
    "        if('.W' in v):\n",
    "            d[v['.I']]=v['.W']\n",
    "        else:\n",
    "            d[v['.I']]=\"\"\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndexerSimple:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.PS=tr.PorterStemmer() \n",
    "        self.index={}\n",
    "        self.indexReverse={}\n",
    "    \n",
    "    def indexation(self,T):\n",
    "        P=Parser()\n",
    "        P.parser(T)      \n",
    "        index={}\n",
    "        M=[]\n",
    "        \n",
    "        for c,v in P.Dic.items():\n",
    "            s=self.PS.getTextRepresentation(v.texte)\n",
    "            index[c]=s\n",
    "\n",
    "            for ca,va in s.items():\n",
    "                if (ca not in M):\n",
    "                    M.append(ca) #on stocke tous les différents mots\n",
    "            \n",
    "            \n",
    "        indexReverse={}\n",
    "        for m in M:\n",
    "            d={}\n",
    "            for c,v in index.items():\n",
    "                if(m in v):\n",
    "                    d[c]=v[m]\n",
    "            indexReverse[m]=d\n",
    "        \n",
    "        self.index=index\n",
    "        self.indexReverse=indexReverse\n",
    "        \n",
    "        return index,indexReverse\n",
    "        \n",
    "    #Avant d'appeller cette méthode il faut appeller la méthode indexation , pour que l'index se cré\n",
    "    def getTfsForDoc(self,d):\n",
    "        return self.index[d]\n",
    "    \n",
    "    # getTfIDFsForDoc retourne la repr´esentation (stem-TFIDF) d’un document a partir de l’index\n",
    "    def getTfIDFsForDoc(self,d):\n",
    "        di={}\n",
    "        N=len(self.index)\n",
    "        for c,v in self.index[d].items():\n",
    "            tf=v\n",
    "            idf=math.log( (1+N) / (1+len(indexReverse[c])) )\n",
    "            x=tf*idf\n",
    "            di[c]=x\n",
    "        return di\n",
    "    \n",
    "    # getTfsForStem qui retourne la repr´esentation (doc-tf) d’un stem a partir de l’index inverse\n",
    "    def getTfsForStem(self,m):\n",
    "            return self.indexReverse[m]\n",
    "    \n",
    "    # méthode getTfIDFsForStem qui retourne la repr´esentation (doc-TFIDF) d’un stem a partir de l’index inverse\n",
    "    def getTfIDFsForStem (self,m):\n",
    "        d={}\n",
    "        N=len(self.index)\n",
    "        for c,v in self.indexReverse[m].items():\n",
    "            r=self.getTfIDFsForDoc(c)\n",
    "            d[c]=r[m]\n",
    "        return d\n",
    "    \n",
    "    # getStrDoc qui retourne la chaine de caract`ere dont est issu un document donne dans le ﬁchier source\n",
    "    def getStrDoc(self,d,T):\n",
    "        D=buildDocumentCollectionRegex2(T)\n",
    "        return D[d]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vu que la taille des fichier est trop grande , pour pouvoir récuperer toute les informations du fichier , il faut lancer jupyter avec la commande : jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000000\n",
    "\n",
    "on peut pas afficher tous lindex d'un coup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I=IndexerSimple()\n",
    "#index,indexReverse=I.indexation('cisi/cisi.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(index['2460'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idem pour l'index inversé , on ne peut pas l'afficher d'un coup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(indexReverse['berg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vu qu'on ne peut afficher tous l'index avec un print , on va stocker les informations dans un fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrer le dictionnaire dans un fichier :\n",
    "with open('index.txt', 'w') as file:\n",
    "    json.dump(index, file)\n",
    "\n",
    "with open('indexInverse.txt', 'w') as file:\n",
    "    json.dump(indexReverse, file)\n",
    " \n",
    "# Charger le dictionnaire depuis un fichier :\n",
    "#with open('notes.txt', 'r') as file:\n",
    "#    notes = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(I.getTfsForDoc(\"201\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
